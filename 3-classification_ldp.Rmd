---
title: "Classification Livre de Poche"
author: "Jérôme THIBAULT"
date: "25/04/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Ajout de la variable à expliquer (collection)

Nous avons fini de préparer notre DTM. Nous la transformons en data frame, et lui ajoutons la variable à expliquer. Ainsi nous pourrons tester différents modèles pour prédire la collection d'appartenance d'un résumé.

```{r ajout variable Y}

dfReviews <- as.data.frame(as.matrix(nonEmptyDtmTf)) # Alternative : on conserve TOUTES les variables, et le supervisé va s'en charger (via les SVM, le Lasso, ...)
dfReviews$Y <- as.factor(nonEmptyDfBookSummaries$collection) # On peut ainsi renseigner la variable Y
head(dfReviews) # 1185 variables car on a ajouté Y
```


## Préparation CARET

Pour tout le protocole de machine learning on utilise la librairie `caret` qui fournit les fonctions pour tout le workflow : construire les échantillons, le prétraitement, les différentes options de validations croisées et un très grand nombre de modèles (https://topepo.github.io/caret/available-models.html)

```{r préparation caret multiclasse}
# install.packages("caret")
library(caret)
library(parallel)
library(doParallel)

splitIndex <- createDataPartition(dfReviews$Y, p = .80, list = FALSE, times = 1)
data.train <- data.frame(dfReviews[ splitIndex,])
data.test  <- data.frame(dfReviews[-splitIndex,])

ytrain <- dfReviews$Y[splitIndex]
ytest  <- dfReviews$Y[-splitIndex]
table(ytrain)/sum(table(ytrain))

table(ytest)/sum(table(ytest))

data.train$Y <- NULL
data.test$Y <- NULL
```



La plupart des modèles choisissent comme classe de positifs, la classe correspondant au premier label, or ici "Imaginaire" arrive en second (ordre alphabétique). Afin que la lecture des différents scores (précision, rappel, spécificicité, sensibilité) soit cohérente avec la détection des positifs (ici les articles liés à l'imaginaire), on inverse les labels. On créé aussi notre split binaire :

```{r préparation classification binaire sur imaginaire}
dfReviewsImaginaireBinaire <- dfReviews %>% mutate(YImaginaire = ifelse(Y == "Imaginaire", "Imaginaire", "Autre")) %>% mutate(Y = NULL)

dfReviewsImaginaireBinaire$YImaginaire <- as.factor(dfReviewsImaginaireBinaire$YImaginaire)


head(dfReviewsImaginaireBinaire$YImaginaire)
levels(dfReviewsImaginaireBinaire$YImaginaire)
dfReviewsImaginaireBinaire$YImaginaire <- relevel(dfReviewsImaginaireBinaire$YImaginaire, "Imaginaire")
head(dfReviewsImaginaireBinaire$YImaginaire)
levels(dfReviewsImaginaireBinaire$YImaginaire)

splitIndex <- createDataPartition(dfReviewsImaginaireBinaire$YImaginaire, p = .80, list = FALSE, times = 1)
data.trainImaginaire <- data.frame(dfReviewsImaginaireBinaire[ splitIndex,])
data.testImaginaire  <- data.frame(dfReviewsImaginaireBinaire[-splitIndex,])

ytrainImaginaire <- dfReviewsImaginaireBinaire$YImaginaire[splitIndex]
ytestImaginaire  <- dfReviewsImaginaireBinaire$YImaginaire[-splitIndex]
table(ytrainImaginaire)/sum(table(ytrainImaginaire))

table(ytestImaginaire)/sum(table(ytestImaginaire))

data.trainImaginaire$YImaginaire <- NULL
data.testImaginaire$YImaginaire <- NULL


seeds <- list(1:4,1:4,1:4,3)

fitControl <- trainControl(method='cv', number=3, returnResamp='none', classProbs = TRUE, summaryFunction = twoClassSummary, allowParallel = TRUE, seeds = seeds)

library(pROC)
```


```{r cm plot utility function}
library(reshape2)
library(ggplot2)

cm.plot <- function(table_cm) {
  tablecm <- round(t(t(table_cm) / colSums(as.matrix(table_cm))*100)) # crée les pourcentages
  tablemelt <- melt(tablecm)
  ggplot(tablemelt, aes(Reference, Prediction)) +
    geom_point(aes(size = value, color=value), alpha=0.8, show.legend=FALSE) +
    geom_text(aes(label = value), color="white") +
    scale_size(range = c(5,25)) +
    scale_y_discrete(limits = rev(levels(tablemelt$Prediction)))+
    theme_bw()
}
```



## Arbre de décision CART

```{r rpart}
library(rpart.plot)

cluster <- makeCluster(detectCores() - 1) # par convention on laisse un coeur pour l'OS
registerDoParallel(cluster)


rpartGridSearch <- expand.grid(cp = seq(0, 0.001, 0.0001))
rpartModel <- train(data.trainImaginaire, ytrainImaginaire, method = "rpart", tuneGrid = rpartGridSearch, trControl = fitControl, metric = 'ROC')
plot(rpartModel)

rpartPrediction <- predict(object = rpartModel$finalModel, data.testImaginaire, type='class')
head(rpartPrediction)
rpartConfusionMatrix <- confusionMatrix(rpartPrediction, ytestImaginaire)

cm.plot(rpartConfusionMatrix$table)

rpartVariableImportance <- varImp(rpartModel$finalModel)
rpartVariableImportanceDf <- data.frame(names = row.names(rpartVariableImportance), imp = rpartVariableImportance[,1])
rpartVariableImportanceDf <- rpartVariableImportanceDf[order(rpartVariableImportanceDf$imp, decreasing = TRUE),]
names(rpartVariableImportanceDf)[2]<-colnames(rpartVariableImportance)[1]
rpartVariableImportanceDf[1:30,]

rpart.plot(rpartModel$finalModel)

rpartConfusionMatrix$overall
rpartConfusionMatrix$byClass


# Ici, on peut choisir le seuil de proba qu'on souhaite qui décidera de la collection de sortie.
# En multiclasse, on pourrait utiliser une matrice de coût.
rpartPredictionProbability <- predict(object = rpartModel$finalModel, data.testImaginaire, type = 'prob')
rpartRocCurve <- roc(response = ytestImaginaire, predictor = rpartPredictionProbability[, "Imaginaire"], levels = rev(levels(ytestImaginaire)))
plot(rpartRocCurve, print.thres = "best")

rpartRocCurve$auc

stopCluster(cluster)
registerDoSEQ()
```



## Forêts aléatoires

```{r random forest}
cluster <- makeCluster(detectCores() - 1) # par convention on laisse un coeur pour l'OS
registerDoParallel(cluster)

gridSearch <- expand.grid(mtry = c(1:17))

rfModel <- train(data.trainImaginaire, ytrainImaginaire, method = "rf", tuneGrid = gridSearch, trControl = fitControl, metric = 'ROC')

rfModel

plot(rfModel) # There are no tuning parameters with more than 1 value : logique on a précisé 1 seul mtry

pred <- predict(object=rfModel$finalModel, data.testImaginaire,type = 'class')
conf.mat <- confusionMatrix(pred, ytestImaginaire)
cm.plot(conf.mat$table)
conf.mat$overall
conf.mat$byClass

imp <- varImp(rfModel$finalModel)
impdf <- data.frame(names = row.names(imp), imp = imp[,1])
impdf <- impdf[order(impdf$imp, decreasing = TRUE),]
names(impdf)[2]<-colnames(imp)[1]
impdf[1:30,]

pred.rf <- predict(object=rfModel$finalModel, data.testImaginaire,type='prob')
rocCurve.rf <- roc(response = ytestImaginaire, predictor = pred.rf[, "Imaginaire"])
rocCurve.rf$auc

stopCluster(cluster)
registerDoSEQ()
```


## Régression logistique pénalisée

On la pénalise car la DTM est de grande dimension et on veut pouvoir sélectionner les variables les plus importantes.

```{r glm pénalisée}
cluster <- makeCluster(detectCores() - 1) # par convention on laisse un coeur pour l'OS
registerDoParallel(cluster)

gridSearch <- expand.grid(alpha=c(0, .5, 1), lambda=c(.1, 1, 10))

glmModel <- train(as.matrix(data.trainImaginaire), ytrainImaginaire, method = "glmnet", tuneGrid = gridSearch, trControl = fitControl, metric = 'ROC', family='binomial')

plot(glmModel)
glmModel$bestTune
glmPrediction <- predict(object = glmModel, as.matrix(data.testImaginaire),type = 'raw')
glmConfusionMatrix <- confusionMatrix(glmPrediction, ytestImaginaire)
cm.plot(glmConfusionMatrix$table)
glmConfusionMatrix$overall
glmConfusionMatrix$byClass

glmVariableImportance <- abs(coef(glmModel$finalModel,glmModel$bestTune$lambda))
glmVariableImportanceDf <- data.frame(names = row.names(glmVariableImportance), imp = glmVariableImportance[,1])
glmVariableImportanceDf <- glmVariableImportanceDf[order(glmVariableImportanceDf$imp, decreasing = TRUE),]
glmVariableImportanceDf[1:30,]

glmPredictionProbability <- predict(object = glmModel, as.matrix(data.testImaginaire),type = 'prob')
glmRocCurve  <- roc(response = ytestImaginaire, predictor = glmPredictionProbability[, "Imaginaire"])
glmRocCurve$auc

stopCluster(cluster)
registerDoSEQ()
```


## SVM linéaire (TODO)

```{r svm svr}

```


## Analyse des courbes ROC des modèles testés

GLM est le meilleur :

```{r analyse courbes ROC}
plot(rpartRocCurve, col = 1)
abline(v = 1)
plot(rocCurve.rf, col = 2, add = TRUE)
plot(glmRocCurve, col = 3, add = TRUE)
legend(0, 0.7, c('rpart','forest','glm'), 1:3)
```



## Régression logistique multinomiale (à réécrire)

```{r nnet}
# install.packages("nnet")
# library(nnet)
# regm <- multinom(genre ~ ., data = train)
# summary(regm)
# table(predict(regm, newdata = test))
# table(predict(regm, newdata = test), test$genre)
```


https://rstudio-pubs-static.s3.amazonaws.com/132792_864e3813b0ec47cb95c7e1e2e2ad83e7.html

```