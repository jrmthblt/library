---
title: "Classification Livre de Poche"
author: "Jérôme THIBAULT"
date: "25/04/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Conversion DTM

```{r ultime preparation}

# PRE-REQUIS : avoir chargé dtm du script précédent (5036 observations, 4823 variables)

# SOIT ON FAIT CA :
review_dtm_tfidf <- removeSparseTerms(dtm, 0.99)

# Peut-être n'est-ce pas utile en supervisé de supprimer les documents
rowTotals <- apply(review_dtm_tfidf , 1, sum) # calcule la somme des termes dans chaque document
review_dtm_tfidf   <- review_dtm_tfidf[rowTotals> 0, ] # retire les documents vides, il peut arriver après nettoyage de se retrouver avec des documents vides, par exemple si on travaille sur des documents très courts type tweet

dfReviews <- as.data.frame(as.matrix(review_dtm_tfidf)) # En ayant retiré des documents vides, comment leur faire désormais correspondre leur genre pour le ML ???

# SOIT CA :
dfReviews <- as.data.frame(as.matrix(dtm)) # Alternative : on conserve TOUTES les variables, et le supervisé va s'en charger (via les SVM, le Lasso, ...)
dfReviews$Y <- as.factor(dfBookSummaries$genre) # On peut ainsi renseigner la variable Y
str(dfReviews)
```


## Préparation CARET

```{r caret}
# install.packages("caret")
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(dfReviews$Y, p = .80, list = FALSE, times = 1)
data.train <- data.frame(dfReviews[ splitIndex,])
data.test  <- data.frame(dfReviews[-splitIndex,])

ytrain <- dfReviews$Y[splitIndex]
ytest  <- dfReviews$Y[-splitIndex]
table(ytrain)/sum(table(ytrain))

table(ytest)/sum(table(ytest))

data.train$Y <- NULL
data.test$Y <- NULL
```


## Forêts aléatoires pour démarrer

```{r random forest}
# stephanie.combes@gmail.com pour des questions
# install.packages("randomForest")
library(randomForest)
fit <- randomForest(ytrain ~ ., data=data.train, importance=TRUE, ntree=300, mtry=7)
varImpPlot(fit)
table(test$genre, predict(fit, test, type="class")) # 80% de données bien classées

table(train$genre, predict(fit, train, type="class")) # 80% de données bien classées

freq = data.frame(sort(colSums(as.matrix(review_dtm_tfidf)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=100, colors=brewer.pal(3, "Dark2"))




```



## Arbre de décision CART

```{r rpart}
library(parallel)
# install.packages("doParallel")
library(doParallel)

cluster <- makeCluster(detectCores() - 1) # par convention on laisse un coeur pour l'OS
registerDoParallel(cluster)

seeds <- list(1:4,1:4,1:4,3)

# Your outcome has 6 levels. The twoClassSummary() function isn't appropriate. On n'est plus en logistique ici.
# On va donc se baser sur une des métriques proposées par l'outil, adapté aux classes étant faiblement représentées :
objControl <- trainControl(method='cv', number=3, returnResamp='none', classProbs = TRUE, allowParallel = TRUE, seeds = seeds)


gridsearch <- expand.grid(cp=seq(0, 0.05, 0.001))
tune <- train(data.train,ytrain,method = "rpart",tuneGrid=gridsearch, trControl =objControl,metric='ROC')
plot(tune)

pred <- predict(object=tune$finalModel, data.test,type='class')
head(pred)
conf.mat <- confusionMatrix(pred, ytest)

library(reshape2)
library(ggplot2)
cm.plot <- function(table_cm){
tablecm <- round(t(t(table_cm) / colSums(as.matrix(table_cm))*100)) # crée les pourcentages
tablemelt <- melt(tablecm)
ggplot(tablemelt, aes(Reference, Prediction)) +
geom_point(aes(size = value, color=value), alpha=0.8, show.legend=FALSE) +
geom_text(aes(label = value), color="white") +
scale_size(range = c(5,25)) +
scale_y_discrete(limits = rev(levels(tablemelt$Prediction)))+
theme_bw()
}
cm.plot(conf.mat$table)

rpart.plot(tune$finalModel)
```


## Régression logistique binaire (obsolète)

```{r glm}
# install.packages("caTools")
library(caTools)


# Test de suppression de la collection Littérature
dfReviews <- subset(dfReviews, dfReviews$genre != "Littérature")

spl = sample.split(dfReviews$genre, SplitRatio = 2/3)
train = subset(dfReviews, spl == TRUE)
test = subset(dfReviews, spl == FALSE)

train$genre <- droplevels(train$genre)
test$genre <- droplevels(test$genre)


reg <- glm(genre ~ ., data = train, family = binomial(logit))
summary(reg)
predictReg <- predict(reg, test, type="response")
table(test$genre, predictReg >= 0.5)
```


## Régression logistique multinomiale

```{r nnet}
# install.packages("nnet")
library(nnet)
regm <- multinom(genre ~ ., data = train)
summary(regm)
table(predict(regm, newdata = test))
table(predict(regm, newdata = test), test$genre)
```


## Forêts aléatoires (obsolète)

```{r random rpart plot}
# 

# install.packages(c('rpart', 'rpart.plot', 'e1071', 'nnet'))
library(rpart)
library(rpart.plot)
library(e1071)
library(nnet)

# Pourquoi sort-il des règles avec des valeurs absolues et non entre 0 et 1 ?
reviewsTree = rpart(genre ~ .,  method = "class", data = train);
prp(reviewsTree)
plotcp(reviewsTree)
# reviewsTreeSimplified <- prune(reviewsTree,cp=0.021)
# prp(reviewsTreeSimplified)
# table(test$genre, predict(reviewsTreeSimplified, test, type="class"))
table(test$genre, predict(reviewsTree, test, type="class"))


# Commencer par les méthodes les plus simples : kmeans et régression linéaire.
# 
# # https://rstudio-pubs-static.s3.amazonaws.com/132792_864e3813b0ec47cb95c7e1e2e2ad83e7.html
# 
```